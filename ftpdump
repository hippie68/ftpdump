#!/bin/bash
# Dumps PS4 games via FTP connection over the network.
# Requires cURL, GNU Wget, and a PS4 FTP server that supports SELF decryption.
# Best results with the FTP payload from https://github.com/hippie68/ps4-ftp.
# For maximum speed, a gigabit cable connection is recommended.
# Get the latest script version at https://github.com/hippie68/ftpdump.
# Please report bugs at https://github.com/hippie68/ftpdump/issues.

# Optional default values: #####################################################

# PS4's IP address
ip=
# PS4's FTP port (FTP payload: 1337)
port=
# Beep when done
beep=false
# How long to beep, in seconds
beep_time=60
# How frequently to beep, in seconds
beep_interval=3

# Functions: ###################################################################

print_usage() {
  cat << EOF
Usage: ${0##*/} [OPTIONS] HOSTNAME|IP_ADDRESS[:PORT] [OUTPUT_DIRECTORY]
   Or: ${0##*/} --extract-pfs|--extract-pkg FILE [OUTPUT_DIRECTORY]

1) Insert a disc and install the game. Optional: visit orbispatches.com
   to download and install a game patch compatible with your firmware.
2) Start a PS4 FTP server (recommended: https://github.com/hippie68/ps4-ftp).
3) Press the PS button to leave the browser.
4) Run the game.
5) Run this script.

To dump more installed games, repeat steps 4) and 5).

Before running the script, make sure the game is completely installed.
Exit the script at any time by pressing CTRL-C.

Options:
  -a, --app          Dump app data.
      --appdb        Dump app.db file and quit.
  -d, --dlc          Dump DLC data.
      --debug        Print debug information.
      --debug-pfs    Print debug information while extracting a PFS image file.
      --dump PATH    Dump specified FTP file or directory and quit.
                     Directories must end with a slash: "PATH/".
      --extract-pfs PFS_IMAGE_FILE
                     Extract a local PFS image file and quit.
      --extract-pkg PKG_FILE
                     Extract a local PKG file and quit.
  -h, --help         Print usage information.
  -k, --keystone     Dump original keystone.
      --keep-trying  Infinitely keep trying to connect.
      --no-decrypt   Do not tell the FTP server to enable SELF decryption.
  -p, --patch        Dump patch data.
  -r, --resume       Resume a previously interrupted download. In rare cases and
                     with most FTP servers this can corrupt decrypted files.
  -s, --sflash       Dump sflash0 file and quit.
      --shutdown     Send the SHUTDOWN command and quit. If the FTP server is a
                     payload that understands the command, it will stop running.
      --use-pfs      Instead of downloading files separately, download and
                     extract the PFS image file.
  -v, --verbose      Print the FTP client/server dialog while downloading files.
EOF
}

debug_message() {
  echo -e "\r\e[95mDEBUG: \e[35m$1\e[39m" >&2
}

warning_message() {
  echo -e "\r\e[93mWARNING: $1\e[39m" >&2
}

critical_message() {
  echo -e "\r\e[91mCRITICAL: $1\e[39m" >&2
}

# Parses command line arguments, creating C-like argc and argv; called with $@
build_args() {
  argc=0
  while [[ $1 && $1 != "--" ]]; do
    if [[ $1 == --* ]]; then
      argv[argc++]=$1
    elif [[ $1 == -?* ]]; then
      for ((i = 1; i < ${#1}; i++)); do
        argv[argc++]=-${1:i:1}
      done
    else
      argv[argc++]=$1
    fi
    shift
  done
  while [[ $1 ]]; do
    argv[argc++]=$1
    shift
  done
  [[ $debug ]] && debug_message "Expanded arguments: ${argv[*]}"
}

# Stops all downloads the FTP server might still be trying to send
# Requires the server to support the custom command KILL
kill_downloads() {
  if [[ $kill_switch ]]; then
    curl $curl_options --head --quote KILL "$root" 2> /dev/null
  fi
}

# Properly stops all downloads, then exits the script
# $1: exit code, $2: optional message
clean_exit() {
  kill $(jobs -p) 2> /dev/null
  wait
  kill_downloads
  if [[ -f "$error_file" ]]; then
    if [[ -s "$error_file" ]]; then
      echo "Error log:"
      cat "$error_file"
    fi
    rm "$error_file" 2> /dev/null || echo \
      "Could not remove temporary file \"$error_file\". Please remove it manually." >&2
  fi
  if [[ $2 ]]; then
    echo "$2"
  fi
  exit $1
}

# User has pressed CTRL-C or sent SIGINT otherwise
sigint_exit() {
  clean_exit 0 "Script aborted by user."
}

# Stops the script execution, printing an optional error message $1
# $2 being set means it's a critical bug that needs to be reported
abort() {
  if [[ $1 ]]; then
    echo "$1" >&2
  fi

  if [[ $2 ]]; then
    critical_message "Please report this at https://github.com/hippie68/ftpdump/issues."
  fi

  # If this is the main process (not a job), then clean-exit with final message
  if [[ $BASHPID == $main_pid ]]; then
    clean_exit 1 "Error encountered, script aborted."
  else # End the job
    # Log the message in the error log file
    [[ -f "$error_file" ]] && echo "[$(date)] $1" >> "$error_file"
    exit 1
  fi
}

# Used by the main process to check if errors occured during jobs
check_for_errors() {
  if [[ -s "$error_file" ]]; then
    abort
  fi
}

# Used by the main process before the script exits, as a final job error check
check_for_errors_and_exit() {
  wait
  check_for_errors
  echo "Done."
  exit 0
}

# Called when cURL encounters an error
# $1: optional file name
curl_error() {
  local message="cURL reported error $? (see https://curl.se/libcurl/c/libcurl-errors.html)."
  if [[ $1 ]]; then
    message="\"${1#$root}\": $message"
  fi
  [[ $curl_verbose ]] && echo -e "\e[39m" # Reset verbose color
  abort "$message"
}

# Called when Wget encounters an error
# $1: exit code
wget_error() {
  local e
  case $1 in
    0) e="No problems occured" ;;
    1) e="Generic error code" ;;
    2) e="Parse error" ;;
    3) e="File I/O error" ;;
    4) e="Network failure" ;;
    5) e="SSL verification failure" ;;
    6) e="Username/password authentication failure" ;;
    7) e="Protocol error" ;;
    8) e="Server issued an error response" ;;
    *) e="Unknown error (see https://www.gnu.org/software/wget/manual/html_node/Exit-Status.html" ;;
  esac
  abort "Wget reported error $1: $e."
}

# Portable replacement for GNU realpath
realpath() {
  echo "$(cd "$(dirname "$1")" && pwd)/$(basename "$1")"
}

# Prints an overall progress percentage in front of each download's file name
# while dumping app/patch
print_download_progress() {
  local result=$((downloaded_bytes * 100 / download_size))
  if [[ $result -gt 100 ]]; then
    result=100
  fi
  echo -en "$result% "
}

# $1: expected download size
enable_download_progress() {
  download_size=$1
  downloaded_bytes=0
  download_progress_enabled=1
}

disable_download_progress() {
  echo -en "\e[2K\r"
  unset download_progress_enabled
}

# Downloads a single FTP file $1, overwriting existing files
# (optional: $2: bytes to skip, $3: bytes to download)
dump_file() {
  local new_file=${1##*/}

  [[ $curl_verbose ]] && echo -en "\e[2K\e[36m"

  # Download partial file
  if [[ $2 ]]; then
    curl $curl_options $curl_verbose --silent --ignore-content-length \
      "${1//#/%23}" | dd "$dd_options" skip="$2" count="$3" 2> /dev/null \
      > "$new_file" || curl_error "$1"
    kill_downloads
    [[ $curl_verbose ]] && echo -en "\e[39m"
  # Download full file
  else
    while read -r line; do
      [[ $line && $line != *" -> "* ]] && echo "$line"
    done < <(wget --no-verbose $wget_options $wget_resume $wget_verbose \
      "$1" --output-document "$new_file" 2>&1 || wget_error $?)
    echo -e "\e[2K\r\e[39m$new_file"
  fi
}

# Recursively downloads an FTP directory with GNU Wget
# $1: full directory path; must end with "/"
dump_dir() {
  local dir_count=0
  local line
  local i

  # Count number of directories for Wget
  line=${1#$root}
  for ((i = 1; i < ${#line}; i++)); do
    if [[ ${line:$i:1} == "/" ]]; then
      ((dir_count++))
    fi
  done
  [[ $debug ]] && debug_message \
    "Dumping directory \"$line\", cutting $dir_count directories."

  # Download directory recursively
  while read -r line; do
    if [[ $line == *" ->"* ]]; then
      file_name=${line%\"*}
      file_size=${file_name%]*}
      file_size=${file_size##*[}
      file_name=${file_name##*\"}
      if [[ $file_name != *.listing ]]; then # Ignore Wget's temporary files
        echo -e "\e[2K\r$file_name"
        # Update download progress
        if [[ $download_progress_enabled ]]; then
          ((downloaded_bytes += file_size))
          print_download_progress
        fi
      fi
    elif [[ $wget_verbose && $line != "" ]]; then
      echo -e "\e[36m$line\e[39m"
    fi
  done < <(wget --cut-dirs $dir_count --no-host-directories --no-parent \
    --no-verbose --recursive $wget_options $wget_resume $wget_verbose \
    --level inf "$1" 2>&1 || wget_error $?)
}

# Enables SELF decryption, which the FTP server must support
enable_decryption() {
  curl -v --silent --quote DECRYPT "$root" 2>&1 \
    | grep "SELF decryption enabled" > /dev/null
  if [[ $? != 0 ]]; then
    curl -v --silent --quote DECRYPT "$root" 2>&1 \
      | grep "SELF decryption enabled" > /dev/null
    if [[ $? != 0 && ! $goldhen_2 ]]; then
      echo "Could not enable SELF decryption. Please try a different FTP server or ignore this by using option --no-decrypt." >&2
      clean_exit 1
    fi
  fi

  if [[ $? == 0 ]]; then
    [[ $debug ]] && debug_message "Server-side SELF decryption is enabled."
  fi
}

# Sets global variable $download_size to size of FTP file $1, in bytes
get_download_size() {
  download_size=$(curl $curl_options --silent --head "$1" \
    | grep "Content-Length")
  if [[ $? -eq 0 ]]; then
    download_size=${download_size#* }
    download_size=${download_size%[^0-9]*}
  else
    download_size=0
  fi
}

# Checks if keystone $1 is fake
check_keystone() {
  local i
  local string

  for ((i = 32; i < 64; i++)); do
    IFS= read -rd "" byte < <(dd bs=1 count=1 skip=$i if="$1" 2>/dev/null)
    string+=$(printf "%x" "'$byte")
  done
  if [[ $string == \
    294a5ed06db170618f2eed8c424b9d828879c080cc66fbc4864f69e974deb856 ]]; then
    warning_message "Keystone is not original."
  fi
}

# PKG extraction: --------------------------------------------------------------

# Returns a 4-byte integer, read from file $1 at offset $2 in big-endian
read_integer() {
  local result=0
  local byte
  local i

  for i in {0..3}; do
    IFS= read -rd "" byte < <(dd bs=1 count=1 skip=$(($2 + i)) if="$1" \
      2> /dev/null)
    byte=$(printf "%d" "'$byte")
    result=$((result + 256 ** (3 - i) * byte))
  done

  echo $result
}

# Returns a string, read from file $1 at offset $2
read_string() {
  local result
  local byte
  local i=0

  while true; do
    IFS= read -rd "" byte < <(dd bs=1 count=1 skip=$(($2 + i)) if="$1" \
      2> /dev/null)
    if [[ $(printf "%d" "'$byte") != 0 ]]; then
      result+=$byte
    else
      break
    fi
    ((i++))
  done

  echo "$result"
}

# Extracts a single file from PKG file $1
# $2: offset, $3: size, $4: output file name
extract_pkg_file() {
  echo "Extracting $4"
  if [[ $4 == */* ]]; then # Create directory, if necessary
    mkdir -p "${4%/*}"
  fi
  dd if="$1" "$dd_options" skip="$2" count="$3" 2> /dev/null > "$4" || abort \
    "Could not extract file \"$4\"."
}

# Extracts all files from PKG file $1
extract_pkg() {
  local file_table_offset=$(read_integer "$1" $((0x18)))
  local file_count=$(read_integer "$1" $((0x10)))
  local offset=$file_table_offset
  local id
  local filename_offset
  local data_offset
  local size
  local filename
  local unknown_count

  # Loop through all entries
  local i=0
  while [[ $i -lt $file_count ]]; do
    id=$(read_integer "$1" offset)
    filename_offset=$(read_integer "$1" $((offset + 4)))
    data_offset=$(read_integer "$1" $((offset + 16)))
    size=$(read_integer "$1" $((offset + 20)))
    if [[ $id == 512 ]]; then
      filename_table_offset=$data_offset
    fi

    # Extract entries that are files
    if [[ $id -ge 1024 ]]; then
      # For files that have no name, create file names
      if [[ $id -lt 4096 ]]; then
        case $id in
          1024) filename=license.dat ;; # 0x400
          1025) filename=license.info ;;
          1026) filename=nptitle.dat ;;
          1027) filename=npbind.dat ;;
          1028) filename=selfinfo.dat ;;
          1030) filename=imageinfo.dat ;;
          1031) filename=target-deltainfo.dat ;;
          1032) filename=origin-deltainfo.dat ;;
          1033) filename=psreserved.dat ;;
             *) filename=UNKNOWN_$((unknown_count++))
                printf "WARNING: No file name known for file ID \"%#x\".\n" $id >&2
                printf "         Using file name \"%s\".\n" "$filename" >&2
                ;;
        esac
      # For other files, read existing file names
      elif [[ $filename_table_offset && $filename_offset -gt 0 ]]; then
        filename=$(read_string "$1" $((filename_table_offset + filename_offset)))
      fi
      # Extract file
      if [[ ! -e "$filename" ]]; then
        extract_pkg_file "$1" $data_offset $size "$filename"
      else
        [[ $debug ]] && debug_message \
          "Warning: file already exists: \"$filename\" (skipped)."
      fi
    fi

    if [[ $debug ]]; then
      debug_message "$(printf "ID: %#x\n" $id)"
      debug_message "Filename offset: $filename_offset"
      debug_message "Data offset: $data_offset"
      debug_message "Size: $size"
    fi

    ((i++))
    ((offset += 32))
  done
}

# Dumps and extracts the body files of PKG file $1
dump_and_extract_pkg() {
  local pkg_filename=${1##*/}

  echo "Preparing extraction of $pkg_filename ..."

  # Test how much PKG data should be downloaded
  [[ $debug ]] && debug_message \
    "Dumping 48 bytes from $pkg_filename to get body size."
  dump_file "$1" 0 48
  body_offset=$(read_integer "$pkg_filename" 36)
  [[ $debug ]] && debug_message "Body offset: $body_offset"
  body_size=$(read_integer "$pkg_filename" 44)
  [[ $debug ]] && debug_message "Body size: $body_size"

  # Download PKG body and extract PKG files
  [[ $debug ]] && debug_message \
    "Dumping body from $pkg_filename ($((body_offset + body_size)) bytes)."
  dump_file "$1" 0 $((body_offset + body_size))
  extract_pkg "$pkg_filename"

  rm "$pkg_filename" || abort \
    "Could not remove temporary file \"$pkg_filename\"."
}

# Checks for and replaces encrypted trophy files from within ./sce_sys/
replace_encrypted_trophies() {
  local i=0
  local magic_number
  local trophy_dirs
  local trophy_file

  # Check previously downloaded npbind.dat for trophy directory names
  readarray -t trophy_dirs < <(grep -aoE NPWR[0-9]{5}_[0-9]{2} npbind.dat)
  [[ $debug ]] && debug_message \
    "Trophy directories found in npbind.dat: ${trophy_dirs[*]}"

  for trophy_file in trophy/trophy[0-9][0-9].trp; do
    # Quit if no trophy files exist
    if [[ ! -f $trophy_file ]]; then
      return
    fi

    echo "Checking trophy files for encryption ..."

    read magic_number < <(dd if="$trophy_file" bs=1 count=3 2> /dev/null)

    if [[ $magic_number == $(printf "\xdc\xa2\x4d") ]]; then
      echo "File \"${trophy_file##*/}\" is not encrypted."
    else
      echo "File \"${trophy_file##*/}\" is encrypted."
      if [[ ${trophy_dirs[$i]} ]]; then
        echo "Replacing \"${trophy_file##*/}\" with unencrypted version."
        [[ $debug ]] && debug_message \
          "Copying from trophy directory \"${trophy_dirs[$i]}\""
        dump_file "$root/user/trophy/conf/${trophy_dirs[$i]}/TROPHY.TRP" \
          > /dev/null
        mv TROPHY.TRP "$trophy_file" || abort
      else
        echo
          critical_message \
            "Could not find unencrypted version of \"${trophy_file##*/}\"." >&2
      fi
    fi

    ((i++))
  done
}

# PFS extraction: --------------------------------------------------------------

readonly INODE_SIZE=168

# Returns an integer, read from file $1 at offset $2 in little endian
# $3: length in bytes
read_int() {
  local result=0
  local byte
  local i

  for ((i = 0; i < $3; i++)); do
    IFS= read -rd "" byte < <(dd bs=1 count=1 skip=$(($2 + i)) if="$1" 2>/dev/null)
    byte=$(printf "%d" "'$byte")
    result=$((result + 256 ** i * byte))
  done

  echo $result
}

# Recursively extracts directories and files from decrypted PFS image file $1
# $2: inode index; $1 must have an absolute path
extract_pfs_dir() {
  local number_of_blocks=$(read_int "$1" \
    $((block_size + INODE_SIZE * $2 + 96)) 4)
  local direct_blocks=$(read_int "$1" \
    $((block_size + INODE_SIZE * $2 + 100)) 4)
  local offset=$((block_size * direct_blocks))

  if [[ $debug_pfs ]]; then
    debug_message "Entering new directory (inode $2)"
    debug_message "(Number of blocks: $number_of_blocks)"
    debug_message "Direct blocks: $direct_blocks"
    debug_message "Offset: $offset"
  fi

  local cur_block
  for ((cur_block = 0; cur_block < number_of_blocks; cur_block++)); do
    while true; do
      local dirent_inode_index=$(read_int "$1" $offset 4)
      # Leave current block if no more directory entries
      if [[ $dirent_inode_index == 0 ]]; then
        [[ $debug_pfs ]] && debug_message \
          "No more directory entries in block $cur_block"
        break
      fi

      local dirent_type=$(read_int "$1" $((offset + 4)) 4)
      local dirent_filename_len=$(read_int "$1" $((offset + 8)) 4)
      local dirent_size=$(read_int "$1" $((offset + 12)) 4)
      local dirent_filename=$(read_string "$1" $((offset + 16)))

      if [[ $debug_pfs ]]; then
        debug_message "Reading inode $2, block $cur_block, directory entry $i"
        debug_message "  -> Dirent inode index: $dirent_inode_index"
        debug_message "  -> Dirent type: $dirent_type"
        debug_message "  -> Dirent file name length: $dirent_filename_len"
        debug_message "  -> Dirent size: $dirent_size"
        debug_message "  -> Dirent file name: $dirent_filename"
      fi

      # Extract file or create directory
      case $dirent_type in
        2) # File
          if [[ $2 -ne $superroot_inode_index ]]; then
            if [[ ! -e "$dirent_filename" ]]; then
              check_for_errors
              # Wait if currently too many files are being extracted
              if [[ $(jobs -r | wc -l) -ge 2 ]]; then
                wait -n
              fi
              # Extract file in the background
              {
                echo "Extracting $dirent_filename"
                local file_size=$(read_int "$1" $((block_size + \
                  dirent_inode_index * INODE_SIZE + 8)) 8)
                [[ $debug_pfs ]] && debug_message "File size: $file_size"
                local file_offset=$((block_size * $(read_int "$1" \
                  $((block_size + dirent_inode_index * INODE_SIZE + 100)) 4)))
                [[ $debug_pfs ]] && debug_message "File offset: $file_offset"
                dd if="$1" $dd_options skip=$file_offset count=$file_size \
                  2> /dev/null > "$dirent_filename" || abort \
                  "Error while extracting file \"$dirent_filename\"."
              } &
            else
              [[ $debug ]] && debug_message \
                "Warning: File already exists: \"$dirent_filename\" (skipped)."
            fi
          fi
          ;;
        3) # Directory
          if [[ $2 -eq $superroot_inode_index ]]; then
            extract_pfs_dir "$1" $dirent_inode_index # Extract true root dir
          else
            echo "Extracting $dirent_filename/"
            mkdir --parents "$dirent_filename" || abort
            cd "$dirent_filename" || abort
            extract_pfs_dir "$1" $dirent_inode_index # Extract next directory
            cd .. || abort
            [[ $debug_pfs ]] && debug_message \
              "Returning to previous directory (inode $2)"
          fi
          ;;
      esac

      offset=$((offset + dirent_size))
    done
  done
}

# Extracts all files from PFS image file $1
extract_pfs_image() {
  [[ $debug ]] && debug_message "Extracting PFS image file \"$1\"."
  superroot_inode_index=$(read_int "$1" 72 8)
  block_size=$(read_int "$1" 32 4)
  extract_pfs_dir "$(realpath "$1")" $superroot_inode_index
  echo "Waiting for extraction to finish ..."
  wait
  check_for_errors
}

# Downloads and extracts PFS image file $1
dump_and_extract_pfs_image() {
  echo "Downloading PFS image file ..."

  curl $curl_options $curl_resume $curl_verbose --progress-bar --remote-name \
    "$1" || curl_error "$1"
  extract_pfs_image "pfs_image.dat"

  rm "pfs_image.dat" || abort \
    "Could not remove temporary file \"pfs_image.dat\"."
}

# Replaces the PFS image dump's encrypted files with decrypted versions
# $1: FTP path to compare current directory with
replace_encrypted_files() {
  echo "Replacing encrypted files ..."

  find . -type f -print0 | while read -d $'\0' file_path; do
    file_name=${file_path#./}
    [[ $debug ]] && debug_message "Checking $file_name"
    magic_number=$(read_integer "$file_name" 0)
    # File is encrypted
    if [[ $magic_number == 1326791965 ]]; then
      dir="${file_path%/*}"
      cd "$dir" || abort
      [[ $debug ]] && debug_message "Replacing encrypted file \"$file_name\"."
      dump_file "$1$file_name"
      cd - > /dev/null || abort
    fi
  done
}

# Main script: #################################################################

LC_ALL=C
main_pid=$BASHPID
decrypt=1
error_file=$(mktemp 2> /dev/null) # Used by the main process to spot failed jobs

trap sigint_exit SIGINT # To catch CTRL-C

# Get options
build_args "$@"
for ((i = 0; i < argc; i++)); do
  if [[ $no_more_args ]]; then
    non_options[noptc++]=${argv[i]}
  else
    case ${argv[i]} in
      --) no_more_args=1 ;;
      -a|-g|--app|--game|--app-only) dump_app=1 ;;
      --appdb) dump_appdb=1 ;;
      -d|--ac|--dlc|--dlc-only) dump_dlc=1 ;;
      --dump)
        if [[ $((++i)) -lt argc ]]; then
          dump_path=${argv[i]}
        else
          echo "Missing argument for option --dump." >&2
          clean_exit 1
        fi
        ;;
      --debug) debug=1 ;;
      --debug-pfs) debug_pfs=1 ;;
      --extract-pfs)
        pfs_extraction_mode=1
        if [[ $((++i)) -lt argc ]]; then
          if [[ ! $noptc ]]; then
            non_options[noptc++]=${argv[i]}
          else
            echo "First non-option argument needs to follow --extract-pfs." >&2
            print_usage >&2
            clean_exit 1
          fi
        else
          echo "Missing argument for option --extract-pfs." >&2
          clean_exit 1
        fi
        ;;
      --extract-pkg)
        pkg_extraction_mode=1
        if [[ $((++i)) -lt argc ]]; then
          if [[ ! $noptc ]]; then
            non_options[noptc++]=${argv[i]}
          else
            echo "First non-option argument needs to follow --extract-pkg." >&2
            print_usage >&2
            clean_exit 1
          fi
        else
          echo "Missing argument for option --extract-pkg." >&2
          clean_exit 1
        fi
        ;;
      -h|--help)
        print_usage
        clean_exit 0
        ;;
      -k|--keystone) dump_keystone=1 ;;
      --keep-trying)
        curl_options+=" --retry 999999 --retry-delay 1 --retry-max-time 0"
        wget_options+=" -t inf "
        ;;
      --no-decrypt) unset decrypt ;;
      -p|--patch|--patch-only) dump_patch=1 ;;
      -r|--resume)
        curl_resume="-C -"
        wget_resume=-c
        ;;
      -s|--sflash|--sflash0) dump_sflash=1 ;;
      --shutdown) shutdown=1 ;;
      --use-pfs) pfs_extraction_enabled=1 ;;
      -v|--verbose)
        curl_verbose=-v
        wget_verbose=-S
        ;;
      -*)
        echo "Unknown option: ${argv[i]}" >&2
        print_usage >&2
        clean_exit 1
        ;;
      *) non_options[noptc++]=${argv[i]} ;;
    esac
  fi
done

# Set dd options
dd --version | grep GNU > /dev/null
if [[ $? == 0 ]]; then
  [[ $debug ]] && debug_message "GNU dd detected - using GNU-specific dd options."
  dd_options="iflag=skip_bytes,count_bytes" # For GNU dd; much faster
else
  [[ $debug ]] && debug_message \
    "Non-GNU dd detected - using regular dd options (slow!)."
  dd_options="ibs=1"
fi

# Set output directory
if [[ ${non_options[1]} ]]; then
  output_dir=$(realpath "${non_options[1]}")
  [[ $debug ]] && debug_message "Using output directory \"$output_dir\"."
else
  output_dir=$(realpath .)
  [[ $debug ]] && debug_message "Using current directory as output directory."
fi

# PFS image file extraction (option --extract-pfs)
if [[ $pfs_extraction_mode ]]; then
  pfs_file=$(realpath "${non_options[0]}")
  if [[ ! -f "$pfs_file" ]]; then
    echo "File does not exist: \"$pfs_file\"." >&2
    clean_exit 1
  fi
  mkdir --parents "$output_dir" && cd "$output_dir" || abort
  extract_pfs_image "$pfs_file"
  exit 0
fi

# PKG file extraction (option --extract-pkg)
if [[ $pkg_extraction_mode ]]; then
  pkg_file=$(realpath "${non_options[0]}")
  if [[ ! -f "$pkg_file" ]]; then
    echo "File does not exist: \"$pkg_file\"." >&2
    clean_exit 1
  fi
  mkdir --parents "$output_dir" && cd "$output_dir" || abort
  extract_pkg "$pkg_file"
  exit 0
fi

# Dump everything by default
if [[ ! $dump_app$dump_patch$dump_dlc$dump_keystone$dump_sflash$dump_appdb$dump_path ]]
then
  [[ $debug ]] && debug_message \
    "No dump options specified - enabling app, patch, and DLC dumping."
  dump_app=1 dump_patch=1 dump_dlc=1
fi

# Display the current state of all options
[[ $debug ]] && debug_message "Options: dump_app=$dump_app, \
dump_patch=$dump_patch, dump_dlc=$dump_dlc, dump_keystone=$dump_keystone, \
dump_sflash=$dump_sflash, dump_appdb=$dump_appdb, dump_path=$dump_path, \
decrypt=$decrypt, debug=$debug, debug_pfs=$debug_pfs, \
curl_options=$curl_options, curl_verbose=$curl_verbose, \
wget_options=$wget_options, wget_verbose=$wget_verbose, \
pfs_extraction_enabled=$pfs_extraction_enabled"

# Set FTP prefix
if [[ ${non_options[0]} ]]; then
  ip=${non_options[0]%:*}
fi
if [[ ${non_options[0]} == *:* ]]; then
  port=${non_options[0]#*:}
fi
if [[ ! $port ]]; then
  port=1337
fi
if [[ ! $ip ]]; then
  echo "Please specify a hostname or an IP address." >&2
  print_usage >&2
  clean_exit 1
fi
root="ftp://$ip:$port"
root=${root%/}
[[ $debug ]] && debug_message "Using FTP server \"$root\"."

# Check for cURL
if ! curl --version &> /dev/null; then
  echo "cURL not found, which is required to run the script. Please install cURL and try again." >&2
  clean_exit 1
fi

# Check for Wget
if ! wget --version &> /dev/null; then
  echo "Wget not found, which is required to run the script. Please install GNU Wget and try again." >&2
  if [[ $(cat /proc/version 2> /dev/null) == *Microsoft* ]]; then
    echo "Try to install it by opening a Windows command prompt and entering \"wsl -e sudo apt install wget\"." >&2
  fi
  clean_exit 1
fi

# Exit if FTP server is not running or does not reply within 5 seconds
[[ $debug ]] && debug_message "Checking FTP connection ..."
reply=$(curl --verbose --max-time 5 --silent --head "$root/" 2>&1 > /dev/null)
case $? in
  0) ;;
  6) abort "Could not resolve host \"$ip\". Please fix your computer's and/or router's DNS settings or enter an IP address." ;;
  7) abort "Could not connect to FTP server. Is it running, and are IP address and port correct?" ;;
  *) curl_error ;;
esac

# Check for GoldHEN FTP server
if echo "$reply" | grep "GoldHEN .*v2" > /dev/null; then
  [[ $debug ]] && debug_message "GoldHEN 2.x FTP server detected."
  goldhen_2=1
fi
unset reply

# Send SHUTDOWN command and quit
if [[ $shutdown ]]; then
  if curl --head --quote SHUTDOWN "$root" 2> /dev/null; then
    echo "SHUTDOWN command successfully sent."
    exit 0
  else
    warning_message "Server does not support the SHUTDOWN command."
    clean_exit 1
  fi
fi

# Check for KILL command support
if curl --head --quote KILL "$root" 2> /dev/null; then
  [[ $debug ]] && debug_message \
    "Server supports the KILL command, which is great."
  kill_switch=1;
elif [[ ! $goldhen_2 ]]; then
  warning_message \
    "Server does not support the KILL command - subsequent dumps may become slower each time."
fi

# Create output directory
mkdir --parents "$output_dir" && cd "$output_dir" || abort

# Single-file dumps  -----------------------------------------------------------

# Database
if [[ $dump_appdb ]]; then
  dump_file "$root/system_data/priv/mms/app.db"
  check_for_errors_and_exit
fi

# sflash0
if [[ $dump_sflash ]]; then
  dump_file "$root/dev/sflash0"
  check_for_errors_and_exit
fi

# Enable decryption, which might be needed from now on
if [[ $decrypt ]]; then
  enable_decryption
else
  [[ $debug ]] && debug_message \
    "Not telling the server to enable SELF decryption." >&2
fi

# User-provided file or directory
if [[ $dump_path ]]; then
  if [[ ${dump_path##*/} ]]; then
    [[ $debug ]] && debug_message "Treating as file: \"$dump_path\""
    dump_file "$root$dump_path"
  else
    [[ $debug ]] && debug_message "Treating as directory: \"$dump_path\""
    dump_dir "$root$dump_path"
  fi
  check_for_errors_and_exit
fi

#-------------------------------------------------------------------------------

# For other dumps, get Title ID
title_id=$(curl $curl_options --silent "$root/mnt/sandbox/" \
  | grep -E " CUSA[0-9]{5}_")
title_id=${title_id##* }
title_id=${title_id%_*}
if [[ $title_id != CUSA[0-9][0-9][0-9][0-9][0-9] ]]; then
  echo "Could not retreive Title ID. Is the game started?" >&2
  clean_exit 1
fi

# Dump keystone ----------------------------------------------------------------

if [[ $dump_keystone ]]; then
  cd "$output_dir" || abort
  echo "Dumping $title_id keystone:"
  mkdir --parents "$title_id-keystone" && cd "$title_id-keystone" || abort

  dump_file "$root/mnt/sandbox/pfsmnt/$title_id-app0/sce_sys/keystone"

  check_keystone keystone
fi

# Dump app data ----------------------------------------------------------------

if [[ $dump_app ]]; then
  get_download_size "$root/mnt/sandbox/pfsmnt/$title_id-app0-nest/pfs_image.dat"

  cd "$output_dir" || abort
  echo "Dumping $title_id app data ($((download_size / 1000000)) MB):"
  mkdir --parents "$title_id-app" && cd "$title_id-app" || abort

  if [[ $pfs_extraction_enabled ]]; then
    dump_and_extract_pfs_image \
      "$root/mnt/sandbox/pfsmnt/$title_id-app0-nest/pfs_image.dat"
    replace_encrypted_files "$root/mnt/sandbox/pfsmnt/$title_id-app0/"
  else
    enable_download_progress "$download_size"
    dump_dir "$root/mnt/sandbox/pfsmnt/$title_id-app0/"
    disable_download_progress
  fi

  mkdir --parents sce_sys && cd sce_sys || abort
  dump_file "$root/System_data/priv/appmeta/$title_id/npbind.dat"
  dump_file "$root/System_data/priv/appmeta/$title_id/nptitle.dat"

  dump_and_extract_pkg "$root/user/app/$title_id/app.pkg"
  replace_encrypted_trophies
fi

# Dump patch data --------------------------------------------------------------

if [[ $dump_patch ]]; then
  [[ $debug ]] && debug_message "Checking if patch data exists."
  curl $curl_options --silent --head \
    "$root/mnt/sandbox/pfsmnt/$title_id-patch0/" > /dev/null
  if [[ $? == 0 ]]; then
    get_download_size \
      "$root/mnt/sandbox/pfsmnt/$title_id-patch0-nest/pfs_image.dat"

    cd "$output_dir" || abort
    echo "Dumping $title_id patch data ($((download_size / 1000000)) MB):"
    mkdir --parents "$title_id-patch" && cd "$title_id-patch" || abort

    if [[ $pfs_extraction_enabled ]]; then
      dump_and_extract_pfs_image \
        "$root/mnt/sandbox/pfsmnt/$title_id-patch0-nest/pfs_image.dat"
      replace_encrypted_files "$root/mnt/sandbox/pfsmnt/$title_id-patch0/"
    else
      enable_download_progress "$download_size"
      dump_dir "$root/mnt/sandbox/pfsmnt/$title_id-patch0/"
      disable_download_progress
    fi

    mkdir --parents sce_sys && cd sce_sys || abort
    dump_file "$root/System_data/priv/appmeta/$title_id/npbind.dat"
    dump_file "$root/System_data/priv/appmeta/$title_id/nptitle.dat"

    dump_and_extract_pkg "$root/user/patch/$title_id/patch.pkg"
    replace_encrypted_trophies
  else
    echo "No patch data found."
  fi
fi

# Dump DLC data ----------------------------------------------------------------

if [[ $dump_dlc ]]; then
  [[ $debug ]] && debug_message "Checking if DLC data exists."
  unset dlc_dirs
  while read line; do
    if [[ $line == d*$title_id*-ac ]]; then
      [[ $debug ]] && debug_message "Found DLC directory ${line##* }"
      dlc_dirs+="${line##* } "
    fi
  done < <(curl $curl_options --silent "$root/mnt/sandbox/pfsmnt/")

  if [[ $dlc_dirs ]]; then
    cd "$output_dir" || abort
    echo "Dumping $title_id DLC data:"
    mkdir --parents "$title_id-dlc" && cd "$title_id-dlc" || abort
    for dir in $dlc_dirs; do
      mkdir "$dir" && cd "$dir" || abort
      dump_dir "$root/mnt/sandbox/pfsmnt/$dir/"
      cd .. || abort
    done
  else
    echo "No DLC data found for $title_id."
  fi
fi

#-------------------------------------------------------------------------------

# Beep when done
if [[ $beep == true ]]; then
  echo "Press CTRL-C to stop beeping."
  if [[ ! $beep_time ]]; then
    beep_time=60
  fi
  if [[ ! $beep_interval ]]; then
    beep_interval=3
  fi
  i=0
  while [[ $i -le $beep_time ]]; do
    echo -en "\a"
    sleep $beep_interval
    ((i += beep_interval))
  done
fi

check_for_errors_and_exit
